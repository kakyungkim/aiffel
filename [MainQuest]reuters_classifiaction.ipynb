{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39d61d3",
   "metadata": {},
   "source": [
    "## 19-1. 프로젝트: Vocabulary Size를 변경해서 시도해보기\n",
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일에 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠.\n",
    "\n",
    "중요도가 낮은 단어들까지 포함해 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다.\n",
    "\n",
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다.\n",
    "\n",
    "`(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)`\n",
    "\n",
    "앞서 num_words로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, num_words의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 <unk>로 처리하는 원리였었죠.\n",
    "\n",
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요.\n",
    "\n",
    "### 1. 라이브러리 버전을 확인해 봅니다\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b807fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "3.4.3\n",
      "0.11.2\n",
      "1.21.4\n",
      "1.3.3\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import numpy \n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(seaborn.__version__)\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c10259",
   "metadata": {},
   "source": [
    "**[ 안내 ]**\n",
    "\n",
    "**1. 모든 단어 사용**<br>\n",
    "`(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)`\n",
    "\n",
    "**2. 빈도수 상위 5,000개의 단어만 사용**<br>\n",
    "`(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)`\n",
    "\n",
    "**3. 직접 단어 개수를 설정해서 사용**<br>\n",
    "위 단계에서 5000으로 제시된 num_words를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. 최소 3가지 경우 이상을 실험해 보기를 권합니다.\n",
    "\n",
    ">사용할 모델\n",
    "> 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅\n",
    "\n",
    "**4. 딥러닝 모델과 비교해 보기**<br>\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정 분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9127fe1e",
   "metadata": {},
   "source": [
    "**[ 루브릭 ]**\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "1. 분류 모델의 accuracy가 기준 이상 높게 나왔는가? -> 3가지 단어 개수에 대해 8가지 머신러닝 기법을 적용하여 그중 최적의 솔루션을 도출하였다.\n",
    "2. 분류 모델의 F1 score가 기준 이상 높게 나왔는가? ->\tVocabulary size에 따른 각 머신러닝 모델의 성능변화 추이를 살피고, 해당 머신러닝 알고리즘의 특성에 근거해 원인을 분석하였다.\n",
    "3. 딥러닝 모델을 활용해 성능이 비교 및 확인되었는가?\t-> 동일한 데이터셋과 전처리 조건으로 딥러닝 모델의 성능과 비교하여 결과에 따른 원인을 분석하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb052c9",
   "metadata": {},
   "source": [
    "**[ 실습 ]**\n",
    "\n",
    "### 1. 데이터 로드 및 전처리\n",
    "Reuters 데이터를 num_words에 따라 다양한 단어 수로 로드합니다.\n",
    "\n",
    "모든 단어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3adc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(x_train_all, y_train_all), (x_test_all, y_test_all) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99c634",
   "metadata": {},
   "source": [
    "데이터 전처리 실행<br>\n",
    "preprocess_data를 사용하여 x_train_tfidf와 x_test_tfidf를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff45221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def preprocess_data(x_train, x_test, num_words):\n",
    "    # 단어 인덱스 로드 및 디코딩 설정\n",
    "    word_index = reuters.get_word_index()\n",
    "    index_to_word = {value + 3: key for key, value in word_index.items()}\n",
    "    index_to_word[0] = \"<PAD>\"\n",
    "    index_to_word[1] = \"<START>\"\n",
    "    index_to_word[2] = \"<UNK>\"\n",
    "    index_to_word[3] = \"<UNUSED>\"\n",
    "    \n",
    "    # Token -> Words\n",
    "    decoded_train = [\" \".join([index_to_word.get(idx, \"?\") for idx in sequence]) for sequence in x_train]\n",
    "    decoded_test = [\" \".join([index_to_word.get(idx, \"?\") for idx in sequence]) for sequence in x_test]\n",
    "    \n",
    "    # DTM and TF-IDF\n",
    "    vectorizer = CountVectorizer(max_features=num_words)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_train_dtm = vectorizer.fit_transform(decoded_train)\n",
    "    x_test_dtm = vectorizer.transform(decoded_test)\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "    x_test_tfidf = tfidf_transformer.transform(x_test_dtm)\n",
    "    \n",
    "    return x_train_tfidf, x_test_tfidf\n",
    "\n",
    "# 데이터 로드\n",
    "from tensorflow.keras.datasets import reuters\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "\n",
    "# 데이터 전처리 실행\n",
    "x_train_tfidf, x_test_tfidf = preprocess_data(x_train, x_test, num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bfa38f",
   "metadata": {},
   "source": [
    "빈도수 상위 5,000개의 단어만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527bb8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_5000, y_train_5000), (x_test_5000, y_test_5000) = reuters.load_data(num_words=5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde857a",
   "metadata": {},
   "source": [
    "사용자 정의 단어 개수 설정 (예: 2,000, 7,000, 10,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b66afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_2000, y_train_2000), (x_test_2000, y_test_2000) = reuters.load_data(num_words=2000, test_split=0.2)\n",
    "(x_train_7000, y_train_7000), (x_test_7000, y_test_7000) = reuters.load_data(num_words=7000, test_split=0.2)\n",
    "(x_train_10000, y_train_10000), (x_test_10000, y_test_10000) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd1863",
   "metadata": {},
   "source": [
    "### 2. 모델 학습 및 평가\n",
    "다양한 모델을 학습시키고 정확도를 평가합니다. 주요 단계는 다음과 같습니다:\n",
    "\n",
    "공통 데이터 전처리\n",
    "- 데이터는 단어 인덱스를 벡터로 변환한 후 DTM과 TF-IDF를 생성합니다.\n",
    "- CountVectorizer와 TfidfTransformer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d997bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def preprocess_data(x_train, x_test, num_words):\n",
    "    # Decoding 데이터\n",
    "    word_index = reuters.get_word_index()\n",
    "    index_to_word = {value + 3: key for key, value in word_index.items()}\n",
    "    index_to_word[0] = \"<PAD>\"\n",
    "    index_to_word[1] = \"<START>\"\n",
    "    index_to_word[2] = \"<UNK>\"\n",
    "    index_to_word[3] = \"<UNUSED>\"\n",
    "    \n",
    "    # Token -> Words\n",
    "    decoded_train = [\" \".join([index_to_word.get(idx, \"?\") for idx in sequence]) for sequence in x_train]\n",
    "    decoded_test = [\" \".join([index_to_word.get(idx, \"?\") for idx in sequence]) for sequence in x_test]\n",
    "    \n",
    "    # DTM and TF-IDF\n",
    "    vectorizer = CountVectorizer(max_features=num_words)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    x_train_dtm = vectorizer.fit_transform(decoded_train)\n",
    "    x_test_dtm = vectorizer.transform(decoded_test)\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "    x_test_tfidf = tfidf_transformer.transform(x_test_dtm)\n",
    "    \n",
    "    return x_train_tfidf, x_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b853fdd",
   "metadata": {},
   "source": [
    "**사용 모델**<br>\n",
    "아래 모델을 각각 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c65f2bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Naive Bayes...\n",
      "Naive Bayes Accuracy: 0.6732\n",
      "Training Complement Naive Bayes...\n",
      "Complement Naive Bayes Accuracy: 0.7707\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Accuracy: 0.8037\n",
      "Training Linear SVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy: 0.7734\n",
      "Training Decision Tree...\n",
      "Decision Tree Accuracy: 0.6215\n",
      "Training Random Forest...\n",
      "Random Forest Accuracy: 0.6834\n",
      "Training Gradient Boosting...\n",
      "Gradient Boosting Accuracy: 0.7649\n",
      "Training VotingClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Accuracy: 0.7930\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Voting 구현을 위한 설정 (Voing은 'soft')\n",
    "# 조건1 : 로지스틱회귀(패널티는 'L2')\n",
    "log_reg = LogisticRegression(penalty='l2', random_state=0)\n",
    "#조건 2: Complement Naive Bayes Classifier\n",
    "cnb = ComplementNB()\n",
    "#조건 3: GradientBoosting Classifier\n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# 모델 리스트\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Complement Naive Bayes\": ComplementNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(C=10000, penalty='l2', max_iter=3000),\n",
    "    \"Linear SVC\": LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=0),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=5, random_state=0),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"VotingClassifier\": VotingClassifier(estimators=[('log_reg', log_reg), ('cnb', cnb), ('gb', gb)], voting='soft')\n",
    "}\n",
    "\n",
    "# 각 모델 학습 및 평가\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(x_train_tfidf, y_train)\n",
    "    predicted = model.predict(x_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    results[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e07e8da3",
   "metadata": {},
   "source": [
    "(Accuracy 중간 정리)\n",
    "Naive Bayes: 0.6732\n",
    "Complement Naive Bayes: 0.7707\n",
    "Logistic Regression: 0.8037\n",
    "Linear SVC: 0.7734\n",
    "Decision Tree: 0.6215\n",
    "Random Forest: 0.6834\n",
    "Gradient Boosting: 0.7649\n",
    "VotingClassifier: 0.7930\n",
    "예상과는 다르게 Logistic Regression Accuracy가 가장 높았음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f5377",
   "metadata": {},
   "source": [
    "### 3. 단어 수 변경 실험\n",
    "다양한 num_words 값을 변경하며 데이터 전처리를 다시 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "511f0d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vocabulary Size: 2000 ===\n",
      "Naive Bayes Accuracy with 2000 words: 0.6968\n",
      "Complement Naive Bayes Accuracy with 2000 words: 0.7565\n",
      "Logistic Regression Accuracy with 2000 words: 0.7809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy with 2000 words: 0.7378\n",
      "Decision Tree Accuracy with 2000 words: 0.6242\n",
      "Random Forest Accuracy with 2000 words: 0.7012\n",
      "Gradient Boosting Accuracy with 2000 words: 0.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Accuracy with 2000 words: 0.7805\n",
      "\n",
      "=== Vocabulary Size: 7000 ===\n",
      "Naive Bayes Accuracy with 7000 words: 0.6732\n",
      "Complement Naive Bayes Accuracy with 7000 words: 0.7707\n",
      "Logistic Regression Accuracy with 7000 words: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy with 7000 words: 0.7711\n",
      "Decision Tree Accuracy with 7000 words: 0.6215\n",
      "Random Forest Accuracy with 7000 words: 0.6834\n",
      "Gradient Boosting Accuracy with 7000 words: 0.7618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Accuracy with 7000 words: 0.7930\n",
      "\n",
      "=== Vocabulary Size: 10000 ===\n",
      "Naive Bayes Accuracy with 10000 words: 0.6732\n",
      "Complement Naive Bayes Accuracy with 10000 words: 0.7707\n",
      "Logistic Regression Accuracy with 10000 words: 0.8037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy with 10000 words: 0.7743\n",
      "Decision Tree Accuracy with 10000 words: 0.6215\n",
      "Random Forest Accuracy with 10000 words: 0.6834\n",
      "Gradient Boosting Accuracy with 10000 words: 0.7667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Accuracy with 10000 words: 0.7930\n"
     ]
    }
   ],
   "source": [
    "# 단어 수 실험 (2000, 7000, 10000)\n",
    "for num_words in [2000, 7000, 10000]:\n",
    "    print(f\"\\n=== Vocabulary Size: {num_words} ===\")\n",
    "    x_train_tfidf, x_test_tfidf = preprocess_data(x_train, x_test, num_words=num_words)\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(x_train_tfidf, y_train)\n",
    "        predicted = model.predict(x_test_tfidf)\n",
    "        accuracy = accuracy_score(y_test, predicted)\n",
    "        print(f\"{model_name} Accuracy with {num_words} words: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78311b47",
   "metadata": {},
   "source": [
    "### 4. 딥러닝 모델과 비교\n",
    "LSTM, GRU, 또는 1D-CNN 모델을 사용합니다.<br>\n",
    "공정성을 위해 Word2Vec 등의 pretrained 모델은 사용하지 않습니다.<br>\n",
    "\n",
    "딥러닝 모델 정의 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176b1d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_222/1340460064.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrnn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_rnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1381\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                **kwargs):\n\u001b[1;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "\n",
    "# Define model\n",
    "def create_rnn_model(vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128),\n",
    "        LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(46, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "rnn_model = create_rnn_model(num_words)\n",
    "rnn_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate model\n",
    "rnn_accuracy = rnn_model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "print(\"RNN Model Accuracy:\", rnn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af9926",
   "metadata": {},
   "source": [
    "### 5. 결과 분석\n",
    "- 모델별 정확도를 그래프로 시각화하여 비교<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc8cc660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.title(\"Model Accuracy by Vocabulary Size\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d89de",
   "metadata": {},
   "source": [
    "- 단어 수 변경에 따른 정확도 변화를 테이블로 정리합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e21145",
   "metadata": {},
   "source": [
    "| Vocabulary Size | 2000 |\n",
    "| ------------------ | ------ |\n",
    "| Naive Bayes | 0.6968 |\n",
    "| Complement Naive Bayes | 0.7565 |\n",
    "| Logistic Regression | 0.7809 |\n",
    "| Linear SVC | 0.7378 |\n",
    "| Decision Tree | 0.6242 |\n",
    "| Random Forest | 0.7012 |\n",
    "| Gradient Boosting | 0.7538 |\n",
    "| Voting Classifier | 0.7805 |\n",
    "\n",
    "| Vocabulary Size | 7000 |\n",
    "| ------------------ | ------ |\n",
    "| Naive Bayes | 0.6732 |\n",
    "| Complement Naive Bayes | 0.7707 |\n",
    "| Logistic Regression | 0.8037 |\n",
    "| Linear SVC | 0.7711 |\n",
    "| Decision Tree | 0.6215 |\n",
    "| Random Forest | 0.6834 |\n",
    "| Gradient Boosting | 0.7618 |\n",
    "| Voting Classifier | 0.7930 |\n",
    "\n",
    "| Vocabulary Size | 10000 |\n",
    "| ------------------ | ------ |\n",
    "| Naive Bayes | 0.6732 |\n",
    "| Complement Naive Bayes | 0.7707 |\n",
    "| Logistic Regression | 0.8037 |\n",
    "| Linear SVC | 0.7743 |\n",
    "| Decision Tree | 0.6215 |\n",
    "| Random Forest | 0.6834 |\n",
    "| Gradient Boosting | 0.7667 |\n",
    "| Voting Classifier | 0.7930 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a95c63b",
   "metadata": {},
   "source": [
    "- 딥러닝과 머신러닝 모델의 성능 차이를 논의<br>\n",
    "에러 발생으로 추후 진행 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb6f1dc",
   "metadata": {},
   "source": [
    "결론\n",
    "- 가장 높은 정확도인 0.8037을 보인 모델은 Logistic Regression 으로 Vocalulary Size는 7000과 10000에서 동일함. 해당 모델에서는 최적의 단어 수가 7000임\n",
    "- 딥러닝과 머신러닝 모델의 성능 차이는 향후 진행 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ce5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
